"use strict";
var __importDefault = (this && this.__importDefault) || function (mod) {
    return (mod && mod.__esModule) ? mod : { "default": mod };
};
Object.defineProperty(exports, "__esModule", { value: true });
const crypto_1 = require("crypto");
const fs_extra_1 = require("fs-extra");
const ramda_1 = require("ramda");
const readline_1 = require("readline");
const json2csv_1 = require("json2csv");
const path_1 = require("path");
const clients_1 = require("../../clients");
const logger_1 = __importDefault(require("../../logger"));
const utils_1 = require("../../utils");
const delete_1 = __importDefault(require("./delete"));
const utils_2 = require("./utils");
const IMPORTS = 'imports';
const [account, workspace] = utils_2.accountAndWorkspace;
const inputSchema = {
    type: 'array',
    items: {
        type: 'object',
        properties: {
            from: {
                type: 'string',
            },
            to: {
                type: 'string',
            },
            endDate: {
                type: 'string',
            },
            type: {
                type: 'string',
                enum: ['PERMANENT', 'TEMPORARY'],
            },
        },
        additionalProperties: false,
        required: ['from', 'to', 'type'],
    },
};
const handleImport = async (csvPath) => {
    const fileHash = (await fs_extra_1.readFile(csvPath)
        .then(data => crypto_1.createHash('md5')
        .update(`${account}_${workspace}_${data}`)
        .digest('hex'))
        .catch(utils_2.handleReadError));
    const metainfo = await fs_extra_1.readJson(utils_2.METAINFO_FILE).catch(() => ({}));
    const importMetainfo = metainfo[IMPORTS] || {};
    let counter = importMetainfo[fileHash] ? importMetainfo[fileHash].counter : 0;
    const routes = await utils_2.readCSV(csvPath);
    utils_2.validateInput(inputSchema, routes);
    const routesList = utils_2.splitJsonArray(routes);
    const bar = utils_2.progressBar('Importing routes...', counter, ramda_1.length(routesList));
    const listener = readline_1.createInterface({ input: process.stdin, output: process.stdout }).on('SIGINT', () => {
        utils_2.saveMetainfo(metainfo, IMPORTS, fileHash, counter);
        console.log('\n');
        process.exit();
    });
    for (const redirects of routesList.splice(counter)) {
        try {
            await clients_1.rewriter.importRedirects(redirects);
        }
        catch (e) {
            await utils_2.saveMetainfo(metainfo, IMPORTS, fileHash, counter);
            listener.close();
            throw e;
        }
        counter++;
        bar.tick();
    }
    logger_1.default.info('Finished!\n');
    listener.close();
    utils_2.deleteMetainfo(metainfo, IMPORTS, fileHash);
    return ramda_1.pluck('from', routes);
};
let retryCount = 0;
exports.default = async (csvPath, options) => {
    const reset = options ? options.r || options.reset : undefined;
    let indexedRoutes;
    if (reset) {
        const indexFiles = await clients_1.rewriter.routesIndexFiles().then(ramda_1.prop('routeIndexFiles'));
        const indexFileNames = ramda_1.pluck('fileName', indexFiles) || [];
        const arr = [];
        for (const name of indexFileNames) {
            arr.push(clients_1.rewriter.routesIndex(name));
        }
        indexedRoutes = ramda_1.compose(ramda_1.pluck('id'), ramda_1.reduce(ramda_1.concat, []))(arr);
    }
    let importedRoutes;
    try {
        importedRoutes = await handleImport(csvPath);
    }
    catch (e) {
        logger_1.default.error('Error handling import');
        const maybeGraphQLErrors = utils_2.showGraphQLErrors(e);
        if (utils_1.isVerbose) {
            console.log(e);
        }
        if (retryCount >= utils_2.MAX_RETRIES || maybeGraphQLErrors) {
            process.exit();
        }
        logger_1.default.error(`Retrying in ${utils_2.RETRY_INTERVAL_S} seconds...`);
        logger_1.default.info('Press CTRL+C to abort');
        await utils_2.sleep(utils_2.RETRY_INTERVAL_S * 1000);
        retryCount++;
        importedRoutes = await module.exports.default(csvPath);
    }
    if (reset) {
        const routesToDelete = ramda_1.difference(indexedRoutes || [], importedRoutes || []);
        if (routesToDelete && !ramda_1.isEmpty(routesToDelete)) {
            const fileName = `.vtex_redirects_to_delete_${Date.now().toString()}.csv`;
            const filePath = `./${fileName}`;
            logger_1.default.info('Deleting old redirects...');
            logger_1.default.info(`In case this step fails, run 'vtex redirects delete ${path_1.resolve(fileName)}' to finish deleting old redirects.`);
            const json2csvParser = new json2csv_1.Parser({ fields: ['from'], delimiter: ';', quote: '' });
            const csv = json2csvParser.parse(ramda_1.map(route => ({ from: route }), routesToDelete));
            await fs_extra_1.writeFile(filePath, csv);
            await delete_1.default(filePath);
            await fs_extra_1.remove(filePath);
        }
    }
    return importedRoutes;
};
